{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "      <th>Method</th>\n",
       "      <th>Host-Header</th>\n",
       "      <th>Connection</th>\n",
       "      <th>Accept</th>\n",
       "      <th>Accept-Charset</th>\n",
       "      <th>Accept-Language</th>\n",
       "      <th>Cache-control</th>\n",
       "      <th>Pragma</th>\n",
       "      <th>User-Agent</th>\n",
       "      <th>Content-Type</th>\n",
       "      <th>POST-Data</th>\n",
       "      <th>GET-Query</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Anomalous</td>\n",
       "      <td>GET</td>\n",
       "      <td>HTTP/1.0</td>\n",
       "      <td>invalid</td>\n",
       "      <td>audio/*;q=0.7, audio/*;q=0.0</td>\n",
       "      <td>*;q=0.6</td>\n",
       "      <td>*;q=0.3</td>\n",
       "      <td>invalid</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Mozilla/9.9 (X11; U; Unix 0.4; el-1y; rv:6.5.0...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NT0cDJacceptnfOF=138695082&amp;wcatUzz=dmH_g&amp;t1lTs...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Anomalous</td>\n",
       "      <td>PUT</td>\n",
       "      <td>HTTP/1.0</td>\n",
       "      <td>close</td>\n",
       "      <td>image/*, image/jpeg;q=0.1</td>\n",
       "      <td>x-mac-greek;q=0.9, euc-cn, x-mac-greek, utf-7</td>\n",
       "      <td>*</td>\n",
       "      <td>invalid</td>\n",
       "      <td>no-cache</td>\n",
       "      <td>Mozilla/9.9 (X11; U; Open BSD i586 4.2; w1-ff;...</td>\n",
       "      <td>application/x-www-form-urlencoded</td>\n",
       "      <td>tcy0wLnt7sw=lTWFH@dvrU&amp;zUEX8MFk=htaccesonDonin...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Anomalous</td>\n",
       "      <td>POST</td>\n",
       "      <td>HTTP/1.0</td>\n",
       "      <td>close</td>\n",
       "      <td>audio/*, audio/basic, text/html;q=0.4</td>\n",
       "      <td>*</td>\n",
       "      <td>non-standard</td>\n",
       "      <td>invalid</td>\n",
       "      <td>no-cache</td>\n",
       "      <td>Mozilla/9.9 (Windows; U; Windows NT 4.9; lf-wc...</td>\n",
       "      <td>application/x-www-form-urlencoded</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Anomalous</td>\n",
       "      <td>GET</td>\n",
       "      <td>HTTP/1.0</td>\n",
       "      <td>close</td>\n",
       "      <td>*/*;q=0.3</td>\n",
       "      <td>x-mac-japanese;q=0.2, iso-8859-3</td>\n",
       "      <td>*</td>\n",
       "      <td>invalid</td>\n",
       "      <td>no-cache</td>\n",
       "      <td>Mozilla/9.9 (Windows; U; Win 9x 9.4; 0t-os; rv...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>imgbo-K@xZdW=tnpp&amp;QVc@=8Ehto&amp;EaEEtEgdis=thxoo8...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Anomalous</td>\n",
       "      <td>GET</td>\n",
       "      <td>HTTP/1.1</td>\n",
       "      <td>close</td>\n",
       "      <td>*/*</td>\n",
       "      <td>*</td>\n",
       "      <td>non-standard</td>\n",
       "      <td>invalid</td>\n",
       "      <td>no-cache</td>\n",
       "      <td>Mozilla/9.9 (Machintosh; U; PPC 8.5; in-hu; rv...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>beqqeAoaUeLxen=%22%29%28targetfilter%3D%28o%3D...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Class Method Host-Header Connection  \\\n",
       "0  Anomalous    GET    HTTP/1.0    invalid   \n",
       "1  Anomalous    PUT    HTTP/1.0      close   \n",
       "2  Anomalous   POST    HTTP/1.0      close   \n",
       "3  Anomalous    GET    HTTP/1.0      close   \n",
       "4  Anomalous    GET    HTTP/1.1      close   \n",
       "\n",
       "                                  Accept  \\\n",
       "0           audio/*;q=0.7, audio/*;q=0.0   \n",
       "1              image/*, image/jpeg;q=0.1   \n",
       "2  audio/*, audio/basic, text/html;q=0.4   \n",
       "3                              */*;q=0.3   \n",
       "4                                    */*   \n",
       "\n",
       "                                  Accept-Charset Accept-Language  \\\n",
       "0                                        *;q=0.6         *;q=0.3   \n",
       "1  x-mac-greek;q=0.9, euc-cn, x-mac-greek, utf-7               *   \n",
       "2                                              *    non-standard   \n",
       "3               x-mac-japanese;q=0.2, iso-8859-3               *   \n",
       "4                                              *    non-standard   \n",
       "\n",
       "  Cache-control    Pragma                                         User-Agent  \\\n",
       "0       invalid       NaN  Mozilla/9.9 (X11; U; Unix 0.4; el-1y; rv:6.5.0...   \n",
       "1       invalid  no-cache  Mozilla/9.9 (X11; U; Open BSD i586 4.2; w1-ff;...   \n",
       "2       invalid  no-cache  Mozilla/9.9 (Windows; U; Windows NT 4.9; lf-wc...   \n",
       "3       invalid  no-cache  Mozilla/9.9 (Windows; U; Win 9x 9.4; 0t-os; rv...   \n",
       "4       invalid  no-cache  Mozilla/9.9 (Machintosh; U; PPC 8.5; in-hu; rv...   \n",
       "\n",
       "                        Content-Type  \\\n",
       "0                                NaN   \n",
       "1  application/x-www-form-urlencoded   \n",
       "2  application/x-www-form-urlencoded   \n",
       "3                                NaN   \n",
       "4                                NaN   \n",
       "\n",
       "                                           POST-Data  \\\n",
       "0                                                NaN   \n",
       "1  tcy0wLnt7sw=lTWFH@dvrU&zUEX8MFk=htaccesonDonin...   \n",
       "2                                                NaN   \n",
       "3                                                NaN   \n",
       "4                                                NaN   \n",
       "\n",
       "                                           GET-Query  \n",
       "0  NT0cDJacceptnfOF=138695082&wcatUzz=dmH_g&t1lTs...  \n",
       "1                                                NaN  \n",
       "2                                                NaN  \n",
       "3  imgbo-K@xZdW=tnpp&QVc@=8Ehto&EaEEtEgdis=thxoo8...  \n",
       "4  beqqeAoaUeLxen=%22%29%28targetfilter%3D%28o%3D...  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv(\"dataset.csv\")\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Method', 'GET'],\n",
       " ['Host-Header', 'HTTP/1.0'],\n",
       " ['Connection', 'invalid'],\n",
       " ['Accept', 'audio/*;q=0.7, audio/*;q=0.0'],\n",
       " ['Accept-Charset', '*;q=0.6'],\n",
       " ['Accept-Language', '*;q=0.3'],\n",
       " ['Cache-control', 'invalid'],\n",
       " ['Pragma', 'nan'],\n",
       " ['User-Agent',\n",
       "  'Mozilla/9.9 (X11; U; Unix 0.4; el-1y; rv:6.5.0) Gecko/72199095'],\n",
       " ['Content-Type', 'nan'],\n",
       " ['POST-Data', 'nan'],\n",
       " ['GET-Query',\n",
       "  'NT0cDJacceptnfOF=138695082&wcatUzz=dmH_g&t1lTs=cJXD0&Ees=ehdoi0ma21shumta&ird4ksfotUq=tWF.ZQ&0zsautyt=imss3iw&utn=Yo4a%2Bj%7Cy+teefl&igiebeetsefet=%29+%28+++%7C++%28displayName%3Dhad*%29++%28name++++%3D+++had*+++%29%28mail%3Dhad*+++%29&ru=rs3O0-hpD&lHle=sC6&eanede=et3Feoptavotgaeen%3Evoc&oyareNneEolwot=n+raD&AImidura=o%3FeRe%40yt+5onX&Ax1ao=3490']]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newData = []\n",
    "row = data.iloc[0]\n",
    "\n",
    "[[col,str(val)] for col, val in row.items() if col != \"Class\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Method', 'GET'],\n",
       " ['Host-Header', 'HTTP/1.0'],\n",
       " ['Connection', 'invalid'],\n",
       " ['Accept', 'audio/*;q=0.7, audio/*;q=0.0'],\n",
       " ['Accept-Charset', '*;q=0.6'],\n",
       " ['Accept-Language', '*;q=0.3'],\n",
       " ['Cache-control', 'invalid'],\n",
       " ['Pragma', 'nan'],\n",
       " ['User-Agent',\n",
       "  'Mozilla/9.9 (X11; U; Unix 0.4; el-1y; rv:6.5.0) Gecko/72199095'],\n",
       " ['Content-Type', 'nan'],\n",
       " ['POST-Data', 'nan'],\n",
       " ['GET-Query',\n",
       "  'NT0cDJacceptnfOF=138695082&wcatUzz=dmH_g&t1lTs=cJXD0&Ees=ehdoi0ma21shumta&ird4ksfotUq=tWF.ZQ&0zsautyt=imss3iw&utn=Yo4a%2Bj%7Cy+teefl&igiebeetsefet=%29+%28+++%7C++%28displayName%3Dhad*%29++%28name++++%3D+++had*+++%29%28mail%3Dhad*+++%29&ru=rs3O0-hpD&lHle=sC6&eanede=et3Feoptavotgaeen%3Evoc&oyareNneEolwot=n+raD&AImidura=o%3FeRe%40yt+5onX&Ax1ao=3490']]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row = data.iloc[0]\n",
    "feature_pairs = [[col,str(val)] for col, val in row.items() if col != \"Class\"]\n",
    "# text = \", \".join(feature_pairs)\n",
    "\n",
    "# text\n",
    "feature_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'DistilBertTokenizer'. \n",
      "The class this function is called from is 'OptimizedDistilBertTokenizer'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: Method: GET, Host-Header: HTTP/1.0, Connection: invalid, Accept: audio/*;q=0.7, audio/*;q=0.0, Accept-Charset: *;q=0.6, Accept-Language: *;q=0.3, Cache-control: invalid, Pragma: nan, User-Agent: Mozilla/9.9 (X11; U; Unix 0.4; el-1y; rv:6.5.0) Gecko/72199095, Content-Type: param1=value1&param2=value2, POST-Data: key1=value1&key2=value2, GET-Query: param1=value1&param2=value2\n",
      "Tokens: ['Method', 'GET', 'Host-Header', 'HTTP/1.0,', 'Connection', 'invalid', 'Accept', '[audio/*;q=0.7]', 'audio', 'q', '=', '=', '0', '0', 'Accept-Charset', '[*;q=0.6]', 'Accept-Language', '[*;q=0.3]', 'Cache-control', 'invalid,', 'Pragma', 'nan,', 'User-Agent', 'Mozilla/9.9 (X11; U; Unix 0.4; el-1y; rv:6.5.0) Gecko/72199095', 'Content-Type', 'param1=value1&param2=value2', 'POST-Data', 'key1=value1&key2=value2', 'GetQuery', 'param1=value1&param2=value2']\n"
     ]
    }
   ],
   "source": [
    "from transformers import DistilBertTokenizer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "\n",
    "class OptimizedDistilBertTokenizer(DistilBertTokenizer):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        # Optimize regex by focusing on critical patterns and reducing backtracking\n",
    "        self.custom_tokenizer = RegexpTokenizer(\n",
    "            r\"Method:\\s*[\\w\\-]+|Host-Header:\\s*[^\\s]+|GET-Query:\\s*[^,]+|\"\n",
    "            \n",
    "            r\"Accept:\\s*[^,]+|Accept-Charset:\\s*[^,]+|Accept-Language:\\s*[^,]+|\"\n",
    "            r\"Cache-control:\\s*[^\\s]+|Pragma:\\s*[^\\s]+|\"\n",
    "            r\"User-Agent:\\s*[^,]+|Content-Type:\\s*[^,]+|POST-Data:\\s*[^,]+|\"\n",
    "            r\"[\\w\\-]+|[:=]\"\n",
    "        )\n",
    "\n",
    "    def tokenize(self, text, **kwargs):\n",
    "        \"\"\"\n",
    "        Tokenizes the input text using optimized logic.\n",
    "        \"\"\"\n",
    "        tokens = self.custom_tokenizer.tokenize(text)\n",
    "        return [\n",
    "            item\n",
    "            for token in tokens\n",
    "            for item in self.process_token(token.strip()) or []\n",
    "        ]\n",
    "\n",
    "    def process_token(self, token):\n",
    "        \"\"\"\n",
    "        Efficiently processes individual tokens.\n",
    "        \"\"\"\n",
    "        if not token or token == \":\":\n",
    "            return None\n",
    "\n",
    "        handlers = self.get_handlers()\n",
    "        for prefix, handler in handlers.items():\n",
    "            if token.startswith(prefix):\n",
    "                return handler(token)\n",
    "\n",
    "        if \":\" in token or \"=\" in token:\n",
    "            return [token, token]\n",
    "\n",
    "        return [token]\n",
    "\n",
    "    def get_handlers(self):\n",
    "        \"\"\"\n",
    "        Predefine handlers to avoid repeated instantiation.\n",
    "        \"\"\"\n",
    "        return {\n",
    "            \"Method:\": lambda t: self._process_key_value(t, \"Method\"),\n",
    "            \"Connection:\": lambda t: self._process_key_value(t, \"Connection\"),\n",
    "            \"Accept:\": lambda t: self._process_generic_list(t, \"Accept\"),\n",
    "            \"Accept-Charset:\": lambda t: self._process_generic_list(t, \"Accept-Charset\"),\n",
    "            \"Accept-Language:\": lambda t: self._process_generic_list(t, \"Accept-Language\"),\n",
    "            \"User-Agent:\": lambda t: self._process_user_agent(t),\n",
    "            \"Host-Header:\": lambda t: [\"Host-Header\", t.split(\":\", 1)[1].strip()],\n",
    "            \"Cache-control:\": lambda t: [\"Cache-control\", t.split(\":\", 1)[1].strip()],\n",
    "            \"Pragma:\": lambda t: [\"Pragma\", t.split(\":\", 1)[1].strip()],\n",
    "            \"Content-Type:\": lambda t: self._process_full_value(t, \"Content-Type\"),\n",
    "            \"POST-Data:\": lambda t: self._process_full_value(t, \"POST-Data\"),\n",
    "            \"GET-Query:\": lambda t: self._process_full_value(t, \"GetQuery\"),\n",
    "        }\n",
    "\n",
    "    def _process_key_value(self, token, key):\n",
    "        \"\"\"\n",
    "        Processes simple key-value pairs.\n",
    "        \"\"\"\n",
    "        _, value = token.split(\":\", 1)\n",
    "        return [key, value.strip()]\n",
    "\n",
    "    def _process_generic_list(self, token, key):\n",
    "        \"\"\"\n",
    "        Processes fields that are lists.\n",
    "        \"\"\"\n",
    "        _, value = token.split(\":\", 1)\n",
    "        items = value.strip().split(\",\")\n",
    "        return [key, f\"[{', '.join(item.strip() for item in items)}]\"]\n",
    "\n",
    "    def _process_user_agent(self, token):\n",
    "        \"\"\"\n",
    "        Processes the User-Agent field.\n",
    "        \"\"\"\n",
    "        key, value = token.split(\":\", 1)\n",
    "        return [key.strip(), value.strip()]\n",
    "\n",
    "    def _process_full_value(self, token, key):\n",
    "        \"\"\"\n",
    "        Processes full value fields without splitting on '&'.\n",
    "        \"\"\"\n",
    "        _, value = token.split(\":\", 1)\n",
    "        return [key, value.strip()]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Prepare Text\n",
    "feature_pairs = [[col, str(val)] for col, val in data.items() if col != \"Class\"]\n",
    "text = \", \".join([f\"{pair[0]}: {pair[1]}\" for pair in feature_pairs])\n",
    "\n",
    "# Tokenize\n",
    "custom_tokenizer = OptimizedDistilBertTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "tokens = custom_tokenizer.tokenize(text)\n",
    "\n",
    "# Output\n",
    "print(\"Text:\", text)\n",
    "print(\"Tokens:\", tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'DistilBertTokenizer'. \n",
      "The class this function is called from is 'CustomDistilBertTokenizer'.\n",
      "2025-01-03 20:52:44,794 - INFO - Loaded data with columns: ['Class', 'Method', 'Host-Header', 'Connection', 'Accept', 'Accept-Charset', 'Accept-Language', 'Cache-control', 'Pragma', 'User-Agent', 'Content-Type', 'POST-Data', 'GET-Query']\n",
      "2025-01-03 20:52:48,387 - INFO - Encoded 2 unique classes\n",
      "2025-01-03 20:52:48,388 - INFO - Processed Text Data: ['Method  GET , Host-Header HTTP/1.0 , Connection invalid , Accept audio/*;q=0.7 , audio/*;q=0.0 , Accept-Charset *;q=0.6 , Accept-Language *;q=0.3 , Cache-control invalid , Pragma  , User-Agent Mozilla/9.9 (X11; U; Unix 0.4; el-1y; rv:6.5.0) Gecko/72199095 , Content-Type  , POST-Data  , GET-Query NT0cDJacceptnfOF=138695082&wcatUzz=dmH_g&t1lTs=cJXD0&Ees=ehdoi0ma21shumta&ird4ksfotUq=tWF.ZQ&0zsautyt=imss3iw&utn=Yo4a%2Bj%7Cy+teefl&igiebeetsefet=%29+%28+++%7C++%28displayName%3Dhad*%29++%28name++++%3D+++had*+++%29%28mail%3Dhad*+++%29&ru=rs3O0-hpD&lHle=sC6&eanede=et3Feoptavotgaeen%3Evoc&oyareNneEolwot=n+raD&AImidura=o%3FeRe%40yt+5onX&Ax1ao=3490'\n",
      " \"Method  PUT , Host-Header HTTP/1.0 , Connection close , Accept image/* , image/jpeg;q=0.1 , Accept-Charset x-mac-greek;q=0.9 , euc-cn , x-mac-greek , utf-7 , Accept-Language * , Cache-control invalid , Pragma no-cache , User-Agent Mozilla/9.9 (X11; U; Open BSD i586 4.2; w1-ff; rv:0.5.7) Gecko/54810742 , Content-Type application/x-www-form-urlencoded , POST-Data tcy0wLnt7sw=lTWFH@dvrU&zUEX8MFk=htaccesonDonin gcxml&opi49=ornIhtaccespca&pzu=t8yb']    | P   |://user[  name/text( )  ='aY&9F-2hztNJkA=zazntrd , GET-Query \"\n",
      " 'Method  POST , Host-Header HTTP/1.0 , Connection close , Accept audio/* , audio/basic , text/html;q=0.4 , Accept-Charset * , Accept-Language non-standard , Cache-control invalid , Pragma no-cache , User-Agent Mozilla/9.9 (Windows; U; Windows NT 4.9; lf-wc; rv:7.3.1) Gecko/75247620 , Content-Type application/x-www-form-urlencoded , POST-Data  , GET-Query '\n",
      " 'Method  GET , Host-Header HTTP/1.0 , Connection close , Accept */*;q=0.3 , Accept-Charset x-mac-japanese;q=0.2 , iso-8859-3 , Accept-Language * , Cache-control invalid , Pragma no-cache , User-Agent Mozilla/9.9 (Windows; U; Win 9x 9.4; 0t-os; rv:7.1.9) Gecko/76358121 , Content-Type  , POST-Data  , GET-Query imgbo-K@xZdW=tnpp&QVc@=8Ehto&EaEEtEgdis=thxoo8n&aaaeo1sslic=ra&6tbaI6ca=..%2F..%2F..%2Fusr%2Fdsqqdsqsd.xml&V60Nr4D6=n6H&qj8y3=1989&Rca=fng&1niaceenxleA=tui'\n",
      " 'Method  GET , Host-Header HTTP/1.1 , Connection close , Accept */* , Accept-Charset * , Accept-Language non-standard , Cache-control invalid , Pragma no-cache , User-Agent Mozilla/9.9 (Machintosh; U; PPC 8.5; in-hu; rv:1.0.5) Gecko/56497824 , Content-Type  , POST-Data  , GET-Query beqqeAoaUeLxen=%22%29%28targetfilter%3D%28o%3DNetscapeRoot%29%29&wrAnteHflaxiT=tgilEiy9eitee7o7gt&thooBbl=113635&ovoaaqefN=mctsl8Ttbd&eahwocrsbetns=93&ohikRnraob0dwnt=a-hxKluVwl&fH5NtGtLVVs=76391&ehHndteieEuyase=sHtwo7&noHroOeetii=shoaah&eeuslnrrlesri6=ncaa%2F&zTasnksis6=cetoetr']\n",
      "2025-01-03 20:52:48,389 - INFO - Encoded Labels: [0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "import logging\n",
    "from typing import Optional, Dict, List, Tuple, Any\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from transformers import DistilBertForSequenceClassification, AdamW, DistilBertTokenizer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO, format=\"%(asctime)s - %(levelname)s - %(message)s\"\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "class CustomDistilBertTokenizer(DistilBertTokenizer):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        # Regex pattern to split and process tokens by \":\"\n",
    "        self.custom_tokenizer = RegexpTokenizer(r\"[\\w\\-]+|[:=]|.+?(?=,|$)\")\n",
    "\n",
    "    def tokenize(self, text, **kwargs):\n",
    "        \"\"\"\n",
    "        Tokenizes the input text using custom logic and splits by \":\".\n",
    "        \"\"\"\n",
    "        tokens = self.custom_tokenizer.tokenize(text)\n",
    "        processed_tokens = [\n",
    "            processed for token in tokens if (processed := self.process_token(token))\n",
    "        ]\n",
    "        return [\n",
    "            item for sublist in processed_tokens for item in (sublist if isinstance(sublist, list) else [sublist])\n",
    "        ]\n",
    "\n",
    "    def process_token(self, token):\n",
    "        \"\"\"\n",
    "        Processes tokens and handles \":\" as a separator.\n",
    "        \"\"\"\n",
    "        if token == \":\":\n",
    "            return None  # Skip \":\" but ensure it's recognized as a separator\n",
    "\n",
    "        if \":\" in token:\n",
    "            key, value = token.split(\":\", 1)\n",
    "            return [key.strip(), value.strip()]\n",
    "\n",
    "        return [token]\n",
    "\n",
    "    def convert_tokens_to_ids(self, tokens):\n",
    "        \"\"\"\n",
    "        Converts tokens to IDs using the parent's method.\n",
    "        \"\"\"\n",
    "        return super().convert_tokens_to_ids(tokens)\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class DataPreprocessor:\n",
    "    \"\"\"Handles data preprocessing for intrusion detection.\"\"\"\n",
    "\n",
    "    file_path: Path\n",
    "    tokenizer: CustomDistilBertTokenizer\n",
    "    label_encoder: LabelEncoder = LabelEncoder()\n",
    "    data: Optional[pd.DataFrame] = None\n",
    "\n",
    "    def load_data(self) -> pd.DataFrame:\n",
    "        \"\"\"Load and validate data from CSV file.\"\"\"\n",
    "        try:\n",
    "            self.data = pd.read_csv(self.file_path)\n",
    "            logger.info(f\"Loaded data with columns: {list(self.data.columns)}\")\n",
    "            return self.data\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Failed to load data: {e}\")\n",
    "            raise\n",
    "\n",
    "    def _validate_data_loaded(self) -> None:\n",
    "        \"\"\"Validate that data is loaded before processing.\"\"\"\n",
    "        if self.data is None:\n",
    "            self.load_data()\n",
    "\n",
    "    def clean_data(self) -> pd.DataFrame:\n",
    "        \"\"\"Clean the dataset by handling missing values and duplicates.\"\"\"\n",
    "        self._validate_data_loaded()\n",
    "        self.data = self.data.fillna(\"\")\n",
    "        return self.data\n",
    "\n",
    "    def combine_features(self) -> pd.DataFrame:\n",
    "        \"\"\"Combine and tokenize features into a single text field.\"\"\"\n",
    "        self._validate_data_loaded()\n",
    "\n",
    "        def process_row(row: pd.Series) -> str:\n",
    "            feature_pairs = [\n",
    "                f\"{col}: {str(val)}\" for col, val in row.items() if col != \"Class\"\n",
    "            ]\n",
    "            text = \", \".join(feature_pairs)\n",
    "            tokens = self.tokenizer.tokenize(text)\n",
    "            return \" \".join(tokens)\n",
    "\n",
    "        self.data[\"Final\"] = self.data.apply(process_row, axis=1)\n",
    "        return self.data\n",
    "\n",
    "    def encode_labels(self, label_column: str = \"Class\") -> pd.DataFrame:\n",
    "        \"\"\"Encode categorical labels while preserving original values.\"\"\"\n",
    "        self._validate_data_loaded()\n",
    "\n",
    "        if label_column not in self.data.columns:\n",
    "            raise ValueError(f\"Label column '{label_column}' not found\")\n",
    "\n",
    "        self.data[\"Class_encoded\"] = self.label_encoder.fit_transform(\n",
    "            self.data[label_column]\n",
    "        )\n",
    "        logger.info(f\"Encoded {len(self.label_encoder.classes_)} unique classes\")\n",
    "        return self.data\n",
    "\n",
    "    def prepare_all_data(self) -> Tuple[np.ndarray, np.ndarray]:\n",
    "        \"\"\"Execute full data preparation pipeline.\"\"\"\n",
    "        self._validate_data_loaded()\n",
    "\n",
    "        self.clean_data()\n",
    "        self.combine_features()\n",
    "        self.encode_labels()\n",
    "\n",
    "        return self.data[\"Final\"].values, self.data[\"Class_encoded\"].values\n",
    "\n",
    "    def get_label_mapping(self) -> Dict[int, Any]:\n",
    "        \"\"\"Get mapping between encoded and original labels.\"\"\"\n",
    "        if not hasattr(self.label_encoder, \"classes_\"):\n",
    "            raise ValueError(\"Labels not yet encoded\")\n",
    "\n",
    "        return dict(enumerate(self.label_encoder.classes_))\n",
    "\n",
    "\n",
    "# Example Usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Path to dataset\n",
    "    dataset_path = Path(\"dataset.csv\")\n",
    "\n",
    "    # Custom Tokenizer\n",
    "    custom_tokenizer = CustomDistilBertTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "\n",
    "    # Initialize Preprocessor\n",
    "    preprocessor = DataPreprocessor(file_path=dataset_path, tokenizer=custom_tokenizer)\n",
    "\n",
    "    # Prepare Data\n",
    "    X, y = preprocessor.prepare_all_data()\n",
    "\n",
    "    # Output\n",
    "    logger.info(f\"Processed Text Data: {X[:5]}\")\n",
    "    logger.info(f\"Encoded Labels: {y[:5]}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
